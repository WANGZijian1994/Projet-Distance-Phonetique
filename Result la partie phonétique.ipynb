{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphonetics \n",
    "from pyphonetics import Soundex\n",
    "from pyphonetics import Metaphone\n",
    "from pyphonetics import RefinedSoundex\n",
    "import pyjarowinkler\n",
    "from pyjarowinkler import distance\n",
    "import spacy\n",
    "import codecs\n",
    "import pprint\n",
    "import metaphone\n",
    "from metaphone import doublemetaphone\n",
    "import phonetics\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def LD(s,t):\n",
    "    import pprint\n",
    "    if len(s)==0 :\n",
    "        res = len(t)\n",
    "    if len(t)==0:\n",
    "        res = len(s)\n",
    "    dist = [[0 for x in range(len(s)+1)] for x in range(len(t)+1)]\n",
    "    for i in range(len(s)+1):\n",
    "        dist[0][i] = i\n",
    "    for j in range(len(t)+1):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1,len(s)+1):\n",
    "        for j in range(1,len(t)+1):\n",
    "            if s[i-1]==t[j-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            dist[j][i] = min(dist[j-1][i]+1,dist[j][i-1]+1,dist[j-1][i-1]+cost)\n",
    "    res = dist[len(t)][len(s)]\n",
    "    #pprint.pprint(dist)\n",
    "    return res\n",
    "\n",
    "def Similarity_DL(s,t):\n",
    "    return LD(s,t) / max(len(s),len(t))\n",
    "\n",
    "def Distance_Jaro(a,b):\n",
    "    return 1-distance.get_jaro_distance(a, b, winkler=True, scaling=0.1)\n",
    "\n",
    "def Similarity_Word_Vectors(a,b):\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    a1 = nlp.vocab[a]\n",
    "    b1 = nlp.vocab[b]\n",
    "    indice = a1.similarity(b1)\n",
    "    return indice\n",
    "\n",
    "def Distance_Phonetics_Representations(a,b):\n",
    "    rs = RefinedSoundex()\n",
    "    if len(a)==len(b):\n",
    "        return rs.distance(a,b,metric=\"hamming\")\n",
    "    else:\n",
    "        return rs.distance(a,b,metric=\"levenshtein\")\n",
    "\n",
    "def Code_Soundex(a):\n",
    "    soundex = Soundex()\n",
    "    return soundex.phonetics(a)\n",
    "\n",
    "def Comparaison_Soundex(a,b):\n",
    "    soundex = Soundex()\n",
    "    return soundex.sounds_like(a,b)\n",
    "\n",
    "def Similarity_Soundex(a,b):\n",
    "    return Distance_Jaro(Code_Soundex(a),Code_Soundex(b))\n",
    "\n",
    "def Code_Metaphone(a):\n",
    "    metaphone = Metaphone()\n",
    "    return metaphone.phonetics(a)\n",
    "\n",
    "def Similarity_Metaphone(a,b):\n",
    "    return Distance_Jaro(Code_Metaphone(a),Code_Metaphone(b))\n",
    "\n",
    "def Double_Metaphone(a):\n",
    "    return str(phonetics.dmetaphone(a))\n",
    "\n",
    "def ConstruireHTML(liste):\n",
    "    w = open(\"20000-30000.html\", \"w\")\n",
    "    w.write(\"<table border= '1'>\")\n",
    "    for ligne in liste:\n",
    "        w.write(\"<tr><td>\")\n",
    "        w.write(\"</td><td>\".join([str(x) for x in ligne]))\n",
    "        w.write(\"</td><tr>\")\n",
    "    w.write(\"</table>\")\n",
    "    w.close()\n",
    "\n",
    "def Trouver_Paire_Minimale(t):# t est un tuple\n",
    "    for i in range(len(t[0])):\n",
    "        if(t[0][i]!=t[1][i]):\n",
    "            return tuple((t[0][i],t[1][i]))\n",
    "\n",
    "def stockerEnListe(a):\n",
    "    s = []\n",
    "    for couple in a:\n",
    "        s.append(couple)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PR', '')\n",
      "('PR', '')\n",
      "('T', 'TR')\n",
      "('PR', '')\n",
      "('PR', '')\n",
      "('FRTR', '')\n",
      "('FRLR', '')\n"
     ]
    }
   ],
   "source": [
    "print(Double_Metaphone(\"pierre\"))\n",
    "print(Double_Metaphone(\"bière\"))\n",
    "print(Double_Metaphone(\"tier\"))\n",
    "print(Double_Metaphone(\"bière\"))\n",
    "print(Double_Metaphone(\"Pierre\"))\n",
    "print(Double_Metaphone(\"frotter\"))\n",
    "print(Double_Metaphone(\"frôler\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://redac.univ-tlse2.fr/lexiques/glaff.html\n",
    "\n",
    "lien pour le dictionnaire GLAFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement du dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758732\n",
      "758732\n",
      "758732\n",
      "758732\n"
     ]
    }
   ],
   "source": [
    "Mots = []\n",
    "API = []\n",
    "lignes = []\n",
    "traits = []\n",
    "lemme = []\n",
    "Frequence = []\n",
    "\n",
    "fin = codecs.open(\"GLAFF/glaff-1.2.2.txt\",'r',encoding=\"UTF-8\")\n",
    "for line in open(\"GLAFF/glaff-1.2.2.txt\",'r',encoding=\"UTF-8\"):\n",
    "    line = fin.readline()\n",
    "    lignes.append(line)\n",
    "fin.close()\n",
    "\n",
    "for ligne in lignes:\n",
    "    l = ligne.strip().split(\"|\")\n",
    "    if((l[3]!=\"\") and (set(l[-12:-1])!={'0'})):\n",
    "        Mots.append(l[0])\n",
    "        traits.append(l[1])\n",
    "        lemme.append(l[2])\n",
    "        l[3]=l[3].replace('.','')\n",
    "        API.append(l[3])\n",
    "\n",
    "print(len(Mots))\n",
    "print(len(traits))\n",
    "print(len(lemme))\n",
    "print(len(API))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problème 1: Pour les morphologies flexionnelles on ne peux pas lier directement le lemme et la transcription phonétique\n",
    "\n",
    "http://paginaspersonales.deusto.es/abaitua/konzeptu/multext/LEX1_FR.html\n",
    "\n",
    "###### Trouver les formes en masculin singulier\n",
    "\n",
    "###### Diminuer la complexité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('übercélèbre', 'ybœʁselɛbʁ'), ('übercélèbre', 'Afpfs'))\n"
     ]
    }
   ],
   "source": [
    "Mots_API = list(zip(Mots,API))\n",
    "lemme_traits = list(zip(lemme,traits))\n",
    "Mots_API_lemme_traits = list(zip(Mots_API,lemme_traits))\n",
    "M = []\n",
    "L = []\n",
    "T = []\n",
    "A = []\n",
    "print(Mots_API_lemme_traits[0])\n",
    "Information = dict()\n",
    "for i in range(len(Mots_API_lemme_traits)):\n",
    "    #Pour les verbes:\n",
    "    if(Mots_API_lemme_traits[i][1][1]==\"Vmn----\"):\n",
    "        M.append(Mots_API_lemme_traits[i][1][0])\n",
    "        A.append(Mots_API_lemme_traits[i][0][1])\n",
    "        L.append(Mots_API_lemme_traits[i][1][0])\n",
    "        T.append(\"Verbe\")\n",
    "    # Pour les noms communs/propres:\n",
    "    if(Mots_API_lemme_traits[i][1][1]==\"Ncms\"):\n",
    "        M.append(Mots_API_lemme_traits[i][1][0])\n",
    "        A.append(Mots_API_lemme_traits[i][0][1])\n",
    "        L.append(Mots_API_lemme_traits[i][1][0])\n",
    "        T.append(\"Nom\")\n",
    "    # Pour les adjectifs:\n",
    "    if((Mots_API_lemme_traits[i][1][1]==\"Afcms-\")or(Mots_API_lemme_traits[i][1][1]==\"Afpms-\")or(Mots_API_lemme_traits[i][1][1]==\"Ai-ms-\")or(Mots_API_lemme_traits[i][1][1]==\"Ao-ms-\")or(Mots_API_lemme_traits[i][1][1]==\"As-ms-\")):\n",
    "        M.append(Mots_API_lemme_traits[i][1][0])\n",
    "        A.append(Mots_API_lemme_traits[i][0][1])\n",
    "        L.append(Mots_API_lemme_traits[i][1][0])\n",
    "        T.append(\"Adjectif\")\n",
    "    # Pour les adverbes:\n",
    "    if((Mots_API_lemme_traits[i][1][1]==\"Rgp\")or(Mots_API_lemme_traits[i][1][1]==\"Rgc\")or(Mots_API_lemme_traits[i][1][1]==\"Rgc\")or(Mots_API_lemme_traits[i][1][1]==\"Rgn\")):\n",
    "        M.append(Mots_API_lemme_traits[i][1][0])\n",
    "        A.append(Mots_API_lemme_traits[i][0][1])\n",
    "        L.append(Mots_API_lemme_traits[i][1][0])\n",
    "        T.append(\"Adverbe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"CorpusNet.txt\",'w',encoding=\"UTF-8\")as f:\n",
    "    for i in range(len(M)):\n",
    "        s = M[i]+\"|\"+L[i]+\"|\"+T[i]+\"|\"+A[i]\n",
    "        f.write(s)\n",
    "        f.write(\"\\n\")\n",
    "with open(\"Corpus.txt\",'w',encoding=\"UTF-8\")as f:\n",
    "    for i in range(len(M)):\n",
    "        s = L[i]+\"|\"+T[i]+\"|\"+A[i]\n",
    "        f.write(s)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problème 2 Trouver les paires-minimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37580\n",
      "37580\n",
      "37580\n",
      "37580\n",
      "37580\n"
     ]
    }
   ],
   "source": [
    "print(len(M))\n",
    "print(len(A))\n",
    "print(len(T))\n",
    "print(len(L))\n",
    "Corpus = list(zip(list(zip(M,A)),T))\n",
    "print(len(Corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7065\n",
      "7065\n",
      "7065\n",
      "('about', 'adoux') ('abu', 'adu') ('Nom', 'Nom')\n"
     ]
    }
   ],
   "source": [
    "# 10000\n",
    "Corpus = list(zip(list(zip(M,A)),T))\n",
    "Paires_Minimales = []\n",
    "Paires_Minimales_API = []\n",
    "Paires_Minimales_POS = []\n",
    "for i in range(len(M[:10000])):\n",
    "    for j in range(i+1,len(M[:10000])):\n",
    "        if((LD(Corpus[i][0][1],Corpus[j][0][1])==1) and (len(Corpus[i][0][1])==len(Corpus[j][0][1]))):\n",
    "            Paires_Minimales.append(tuple((Corpus[i][0][0],Corpus[j][0][0])))\n",
    "            Paires_Minimales_API.append(tuple((Corpus[i][0][1],Corpus[j][0][1])))\n",
    "            Paires_Minimales_POS.append(tuple((Corpus[i][1],Corpus[j][1])))\n",
    "print(len(Paires_Minimales))\n",
    "print(len(Paires_Minimales_API))\n",
    "print(len(Paires_Minimales_POS))\n",
    "print(Paires_Minimales[211],Paires_Minimales_API[211],Paires_Minimales_POS[211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5233\n",
      "5233\n",
      "5233\n",
      "('croton', 'crottin') ('kʁɔtɔ̃', 'kʁɔtɛ̃') ('Nom', 'Nom')\n"
     ]
    }
   ],
   "source": [
    "# 20000\n",
    "Corpus = list(zip(list(zip(M,A)),T))\n",
    "Paires_Minimales1 = []\n",
    "Paires_Minimales_API1 = []\n",
    "Paires_Minimales_POS1 = []\n",
    "for i in range(10000,20000):\n",
    "    for j in range(i+1,20000):\n",
    "        if((LD(Corpus[i][0][1],Corpus[j][0][1])==1) and (len(Corpus[i][0][1])==len(Corpus[j][0][1]))):\n",
    "            Paires_Minimales1.append(tuple((Corpus[i][0][0],Corpus[j][0][0])))\n",
    "            Paires_Minimales_API1.append(tuple((Corpus[i][0][1],Corpus[j][0][1])))\n",
    "            Paires_Minimales_POS1.append(tuple((Corpus[i][1],Corpus[j][1])))\n",
    "print(len(Paires_Minimales_API1))\n",
    "print(len(Paires_Minimales_POS1))\n",
    "print(len(Paires_Minimales1))\n",
    "print(Paires_Minimales1[211],Paires_Minimales_API1[211],Paires_Minimales_POS1[211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6489\n",
      "6489\n",
      "6489\n",
      "('kinnor', 'quinoa') ('kinɔʁ', 'kinɔa') ('Nom', 'Nom')\n"
     ]
    }
   ],
   "source": [
    "# 30000\n",
    "Corpus = list(zip(list(zip(M,A)),T))\n",
    "Paires_Minimales2 = []\n",
    "Paires_Minimales_API2 = []\n",
    "Paires_Minimales_POS2 = []\n",
    "for i in range(20000,30000):\n",
    "    for j in range(i+1,30000):\n",
    "        if((LD(Corpus[i][0][1],Corpus[j][0][1])==1) and (len(Corpus[i][0][1])==len(Corpus[j][0][1]))):\n",
    "            Paires_Minimales2.append(tuple((Corpus[i][0][0],Corpus[j][0][0])))\n",
    "            Paires_Minimales_API2.append(tuple((Corpus[i][0][1],Corpus[j][0][1])))\n",
    "            Paires_Minimales_POS2.append(tuple((Corpus[i][1],Corpus[j][1])))\n",
    "print(len(Paires_Minimales_API2))\n",
    "print(len(Paires_Minimales_POS2))\n",
    "print(len(Paires_Minimales2))\n",
    "print(Paires_Minimales2[211],Paires_Minimales_API2[211],Paires_Minimales_POS2[211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4668\n",
      "4668\n",
      "4668\n",
      "('regret', 'retrait') ('ʁəgʁɛ', 'ʁətʁɛ') ('Nom', 'Nom')\n"
     ]
    }
   ],
   "source": [
    "# 37580\n",
    "Corpus = list(zip(list(zip(M,A)),T))\n",
    "Paires_Minimales3 = []\n",
    "Paires_Minimales_API3 = []\n",
    "Paires_Minimales_POS3 = []\n",
    "for i in range(30000,37580):\n",
    "    for j in range(i+1,37580):\n",
    "        if((LD(Corpus[i][0][1],Corpus[j][0][1])==1) and (len(Corpus[i][0][1])==len(Corpus[j][0][1]))):\n",
    "            Paires_Minimales3.append(tuple((Corpus[i][0][0],Corpus[j][0][0])))\n",
    "            Paires_Minimales_API3.append(tuple((Corpus[i][0][1],Corpus[j][0][1])))\n",
    "            Paires_Minimales_POS3.append(tuple((Corpus[i][1],Corpus[j][1])))\n",
    "print(len(Paires_Minimales_API3))\n",
    "print(len(Paires_Minimales_POS3))\n",
    "print(len(Paires_Minimales3))\n",
    "print(Paires_Minimales3[211],Paires_Minimales_API3[211],Paires_Minimales_POS3[211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amɔliʁ\n",
      "('m', 's')\n"
     ]
    }
   ],
   "source": [
    "def Trouver_Paire_Minimale(t):# t est un tuple\n",
    "    for i in range(len(t[0])):\n",
    "        if(t[0][i]!=t[1][i]):\n",
    "            return tuple((t[0][i],t[1][i]))\n",
    "print(Paires_Minimales_API[1311][0])\n",
    "print(Trouver_Paire_Minimale(Paires_Minimales_API[1311]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stocker les données et Construire le tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mots10000 = stockerEnListe(Paires_Minimales)\n",
    "APIs10000 = stockerEnListe(Paires_Minimales_API)\n",
    "Traits10000 = stockerEnListe(Paires_Minimales_POS)\n",
    "Mots1000020000 = stockerEnListe(Paires_Minimales1)\n",
    "APIs1000020000 = stockerEnListe(Paires_Minimales_API1)\n",
    "Traits1000020000 = stockerEnListe(Paires_Minimales_POS1)\n",
    "Mots2000030000 = stockerEnListe(Paires_Minimales2)\n",
    "APIs2000030000 = stockerEnListe(Paires_Minimales_API2)\n",
    "Traits2000030000 = stockerEnListe(Paires_Minimales_POS2)\n",
    "Mots3000037580 = stockerEnListe(Paires_Minimales3)\n",
    "APIs3000037580 = stockerEnListe(Paires_Minimales_API3)\n",
    "Traits3000037580 = stockerEnListe(Paires_Minimales_POS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PM2000030000APIs.txt\",'w',encoding = \"UTF-8\")as f:\n",
    "    for ligne in APIs2000030000:\n",
    "        f.write(ligne)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tableau = [[[]for x in range(5)]for y in range(len(Paires_Minimales)+1)]\n",
    "Tableau[0] = [\"Mots\",\"Transcription Phonétique\",\"POS\",\"Double Métaphone\",\"Paires Minimales\"]\n",
    "for i in range(len(Paires_Minimales)):\n",
    "    Tableau[i+1][0]=str(Paires_Minimales[i])\n",
    "    Tableau[i+1][1]=str(Paires_Minimales_API[i])\n",
    "    Tableau[i+1][2]=str(Paires_Minimales_POS[i])\n",
    "    Tableau[i+1][3]=Double_Metaphone(Paires_Minimales[i][0])+\" \"+Double_Metaphone(Paires_Minimales[i][1])\n",
    "    Tableau[i+1][4]=str(Trouver_Paire_Minimale(Paires_Minimales_API[i]))\n",
    "ConstruireHTML(Tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tableau1 = [[[]for x in range(5)]for y in range(len(Paires_Minimales1)+1)]\n",
    "Tableau1[0] = [\"Mots\",\"Transcription Phonétique\",\"POS\",\"Double Métaphone\",\"Paires Minimales\"]\n",
    "for i in range(len(Paires_Minimales1)):\n",
    "    Tableau1[i+1][0]=str(Paires_Minimales1[i])\n",
    "    Tableau1[i+1][1]=str(Paires_Minimales_API1[i])\n",
    "    Tableau1[i+1][2]=str(Paires_Minimales_POS1[i])\n",
    "    Tableau1[i+1][3]=Double_Metaphone(Paires_Minimales1[i][0])+\" \"+Double_Metaphone(Paires_Minimales1[i][1])\n",
    "    Tableau1[i+1][4]=str(Trouver_Paire_Minimale(Paires_Minimales_API1[i]))\n",
    "ConstruireHTML(Tableau1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tableau2 = [[[]for x in range(5)]for y in range(len(Paires_Minimales2)+1)]\n",
    "Tableau2[0] = [\"Mots\",\"Transcription Phonétique\",\"POS\",\"Double Métaphone\",\"Paires Minimales\"]\n",
    "for i in range(len(Paires_Minimales2)):\n",
    "    Tableau2[i+1][0]=str(Paires_Minimales2[i])\n",
    "    Tableau2[i+1][1]=str(Paires_Minimales_API2[i])\n",
    "    Tableau2[i+1][2]=str(Paires_Minimales_POS2[i])\n",
    "    Tableau2[i+1][3]=Double_Metaphone(Paires_Minimales2[i][0])+\" \"+Double_Metaphone(Paires_Minimales2[i][1])\n",
    "    Tableau2[i+1][4]=str(Trouver_Paire_Minimale(Paires_Minimales_API2[i]))\n",
    "ConstruireHTML(Tableau2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tableau3 = [[[]for x in range(5)]for y in range(len(Paires_Minimales3)+1)]\n",
    "Tableau3[0] = [\"Mots\",\"Transcription Phonétique\",\"POS\",\"Double Métaphone\",\"Paires Minimales\"]\n",
    "for i in range(len(Paires_Minimales3)):\n",
    "    Tableau3[i+1][0]=str(Paires_Minimales3[i])\n",
    "    Tableau3[i+1][1]=str(Paires_Minimales_API3[i])\n",
    "    Tableau3[i+1][2]=str(Paires_Minimales_POS3[i])\n",
    "    Tableau3[i+1][3]=Double_Metaphone(Paires_Minimales3[i][0])+\" \"+Double_Metaphone(Paires_Minimales3[i][1])\n",
    "    Tableau3[i+1][4]=str(Trouver_Paire_Minimale(Paires_Minimales_API3[i]))\n",
    "ConstruireHTML(Tableau3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Paires Minimales POS 10000.txt\",'w',encoding=\"UTF-8\")as f:\n",
    "    for ligne in Paires_Minimales_POS:\n",
    "        f.write(str(ligne))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glaffwords.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a6283844e458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glaffwords.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10336\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glaffwords.txt'"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "import codecs\n",
    "import pprint\n",
    "f = codecs.open(\"glaffwords.txt\",'r',\"utf-8\")\n",
    "words = []\n",
    "for i in range(10336):\n",
    "    g=f.readline()\n",
    "    l=g.split(\"|\")\n",
    "    l[-1] = l[-1].replace(\"\\n\",\"\")\n",
    "    words.append(l)\n",
    "f.close()\n",
    "# Pour trouver le vocabulaire \n",
    "words_with_API = []\n",
    "words_without_API = []\n",
    "for word in words:\n",
    "    if len(word)!=4:\n",
    "        words_without_API.append(word)\n",
    "    else:\n",
    "        words_with_API.append(word)\n",
    "# créer un dictionaire qui lie le mot(supprimer les copies) avec leur API\n",
    "Vocabulaire_Informations = dict()\n",
    "for word in words_with_API:\n",
    "    if \";\" in word[3]:\n",
    "        Vocabulaire_Informations[word[2]]=word[3][:word[3].find(\";\")]# Il y a un problème de choix(1/2 pour la transcription ;) que je dois vous dire ce vendredi \n",
    "    else:\n",
    "        Vocabulaire_Informations[word[2]]=word[3]\n",
    "# créer une liste de vocabulaire (2143 mots différents)\n",
    "Vocabulaire = []\n",
    "API = []\n",
    "for word,prononciation in Vocabulaire_Informations.items():\n",
    "    Vocabulaire.append(word)\n",
    "    API.append(prononciation)\n",
    "# créer des samples qui contienent 10 paires de mots différents.Et leur API concerné\n",
    "Sample1 = list(zip(Vocabulaire[:10],Vocabulaire[10:20]))\n",
    "APISample1 = list(zip(API[:10],API[10:20]))\n",
    "Sample2 = list(zip(Vocabulaire[100:110],Vocabulaire[110:120]))\n",
    "APISample2 = list(zip(API[100:110],API[110:120]))\n",
    "Sample3 = list(zip(Vocabulaire[1000:1010],Vocabulaire[2000:2010]))\n",
    "APISample3 = list(zip(API[100:110],API[110:120]))\n",
    "# Il y a beaucoup d'autres samples, ici la taille d'un sample est de 10 paires de mots.\n",
    "# un tableaux de 11 x 10 qui qffichie tous les indices concernant les sons de deux mots choisis.\n",
    "def Tableaux_de_Résultats(Sample,APISample):\n",
    "    Tableaux = [[[]for x in range(10)]for y in range(11)]\n",
    "    T = [[\"Mots:\"],[\"API\"],[\"Soundex\"],[\"Similarity_Soundex\"],[\"Alike?\"],[\"Metaphone\"],[\"Similarity_Metaphone\"],[\"Distance_Levenshtein\"],[\"Similarity Distance Levenshtein\"],[\"Jaro Distance\"]]\n",
    "    Tableaux[0]=T\n",
    "    for i in range(1,11):\n",
    "        Tableaux[i][0]=Sample[i-1]\n",
    "        Tableaux[i][1]=APISample[i-1]\n",
    "        Tableaux[i][2]=(tools.Code_Soundex(Sample[i-1][0]),tools.Code_Soundex(Sample[i-1][1]))\n",
    "        Tableaux[i][3]=tools.Similarity_Soundex(Sample[i-1][0],Sample[i-1][1])\n",
    "        Tableaux[i][4]=tools.Comparaison_Soundex(Sample[i-1][0],Sample[i-1][1])\n",
    "        Tableaux[i][5]=(tools.Code_Metaphone(Sample[i-1][0]),tools.Code_Metaphone(Sample[i-1][1]))\n",
    "        Tableaux[i][6]=tools.Similarity_Metaphone(Sample[i-1][0],tools.Code_Metaphone(Sample[i-1][1]))\n",
    "        Tableaux[i][7]=tools.LD(APISample[i-1][0],APISample[i-1][1])\n",
    "        Tableaux[i][8]=tools.Similarity_DL(APISample[i-1][0],APISample[i-1][1])\n",
    "        Tableaux[i][9]=tools.Distance_Jaro(APISample[i-1][0],APISample[i-1][1])\n",
    "    return Tableaux\n",
    "pprint.pprint(Tableaux_de_Résultats(Sample1,APISample1))\n",
    "pprint.pprint(Tableaux_de_Résultats(Sample2,APISample2))\n",
    "import json\n",
    "j = json.dumps(Tableaux_de_Résultats(Sample2,APISample2),ensure_ascii=False)\n",
    "with codecs.open(\"Résultat.json\",'w',\"utf-8\")as fin:\n",
    "    fin.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
